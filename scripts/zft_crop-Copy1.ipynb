{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'ZFTurbo: https://kaggle.com/zfturbo'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/fish/scripts')\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (sz1, sz2), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('..', 'data', 'fish', 'crop', 'train', fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index)\n",
    "        path = os.path.join('..', 'data', 'fish', 'crop', 'valid', fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id\n",
    "\n",
    "\n",
    "def load_test():\n",
    "    path = os.path.join('..', 'data', 'fish', 'crop', 'test', 'test', '*.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n",
    "    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    result1.to_csv(sub_file, index=False)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data():\n",
    "    train_data, train_target, train_id = load_train()\n",
    "\n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "\n",
    "    print('Reshape...')\n",
    "    train_data = train_data.transpose((0, 3, 1, 2))\n",
    "\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data = train_data / 255\n",
    "    train_target = np_utils.to_categorical(train_target, 8)\n",
    "\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data():\n",
    "    start_time = time.time()\n",
    "    test_data, test_id = load_test()\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.transpose((0, 3, 1, 2))\n",
    "\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data = test_data / 255\n",
    "\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def dict_to_list(d):\n",
    "    ret = []\n",
    "    for i in d.items():\n",
    "        ret.append(i[1])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def get_lrg_layers(conv_layers):\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p),\n",
    "        #MaxPooling2D(),\n",
    "        #Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        #BatchNormalization(axis=1),\n",
    "        #MaxPooling2D(),\n",
    "        #Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        #BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "def run_cross_validation_create_models(nfolds=10):\n",
    "    # input image dimensions\n",
    "    batch_size = 32\n",
    "    nb_epoch = maxepoch\n",
    "    random_state = 51\n",
    "\n",
    "    train_data, train_target, train_id = read_and_normalize_train_data()\n",
    "    \n",
    "    # Set up VGG weights\n",
    "    vgg640 = Vgg16BN((sz1, sz2)).model\n",
    "    vgg640.pop()\n",
    "    vgg640.input_shape, vgg640.output_shape\n",
    "    vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "    conv_trn_feat = vgg640.predict(train_data, batch_size=32, verbose=1)\n",
    "    \n",
    "    \n",
    "    yfull_train = dict()\n",
    "    # kf = KFold(len(train_id), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    valset = pd.read_csv(\"../image_validation_set.csv\")\n",
    "    kf = KFold(int(valset.Cluster.nunique()), n_folds=nfolds, shuffle = True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "    models = []\n",
    "    for train_index, test_index in kf:\n",
    "        model = Sequential(get_lrg_layers(conv_layers))\n",
    "        model.compile(Adam(lr=lrate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        teid = [i for i in valset.file_name.values if valset[valset['file_name']==i]['Cluster'].values[0] in test_index]\n",
    "        trid = [i for i in valset.file_name.values if valset[valset['file_name']==i]['Cluster'].values[0] in train_index]\n",
    "        test_index1 = [i for i in range(len(train_id)) if train_id[i] in teid]\n",
    "        train_index1 = [i for i in range(len(train_id)) if train_id[i] in trid]\n",
    "        X_train = conv_trn_feat[train_index1]\n",
    "        Y_train = train_target[train_index1]\n",
    "        X_valid = conv_trn_feat[test_index1]\n",
    "        Y_valid = train_target[test_index1]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=1),\n",
    "        ]\n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              shuffle=False, verbose=1, validation_data=(X_valid, Y_valid),\n",
    "              callbacks=callbacks)\n",
    "\n",
    "        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        score = log_loss(Y_valid, predictions_valid)\n",
    "        print('Score log_loss: ', score)\n",
    "        sum_score += score*len(test_index)\n",
    "\n",
    "        # Store valid predictions\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    score = sum_score/len(train_data)\n",
    "    print(\"Log_loss train independent avg: \", score)\n",
    "\n",
    "    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) + '_ep_' + str(nb_epoch)\n",
    "    return info_string, models\n",
    "\n",
    "\n",
    "def run_cross_validation_process_test(info_string, models):\n",
    "    batch_size = 16\n",
    "    num_fold = 0\n",
    "    yfull_test = []\n",
    "    test_id = []\n",
    "    nfolds = len(models)\n",
    "\n",
    "    for i in range(nfolds):\n",
    "        model = models[i]\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        test_data, test_id = read_and_normalize_test_data()\n",
    "        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "        yfull_test.append(test_prediction)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "    info_string = 'loss_' + info_string \\\n",
    "                + '_folds_' + str(nfolds)\n",
    "    create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz1, sz2 = 256, 256\n",
    "nf = 128\n",
    "p = 0.3\n",
    "lrate = 1e-4\n",
    "maxepoch = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 1.2.2\n",
      "Read train images\n",
      "Load folder ALB (Index: 0)\n",
      "Load folder BET (Index: 1)\n",
      "Load folder DOL (Index: 2)\n",
      "Load folder LAG (Index: 3)\n",
      "Load folder NoF (Index: 4)\n",
      "Load folder OTHER (Index: 5)\n",
      "Load folder SHARK (Index: 6)\n",
      "Load folder YFT (Index: 7)\n",
      "Read train data time: 15.96 seconds\n",
      "Convert to numpy...\n",
      "Reshape...\n",
      "Convert to float...\n",
      "Train shape: (3307, 3, 256, 256)\n",
      "3307 train samples\n",
      "3307/3307 [==============================] - 102s   \n",
      "Start KFold number 1 from 5\n",
      "Split train:  2586 2586\n",
      "Split valid:  721 721\n",
      "Train on 2586 samples, validate on 721 samples\n",
      "Epoch 1/300\n",
      "2586/2586 [==============================] - 3s - loss: 2.0350 - acc: 0.4524 - val_loss: 2.0660 - val_acc: 0.0527\n",
      "Epoch 2/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.7232 - acc: 0.4362 - val_loss: 1.9814 - val_acc: 0.2316\n",
      "Epoch 3/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.6972 - acc: 0.3650 - val_loss: 1.9080 - val_acc: 0.3370\n",
      "Epoch 4/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.6614 - acc: 0.4018 - val_loss: 1.8089 - val_acc: 0.5104\n",
      "Epoch 5/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.6411 - acc: 0.4432 - val_loss: 1.7116 - val_acc: 0.5187\n",
      "Epoch 6/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.6199 - acc: 0.4571 - val_loss: 1.6394 - val_acc: 0.5229\n",
      "Epoch 7/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.6041 - acc: 0.4714 - val_loss: 1.5874 - val_acc: 0.5229\n",
      "Epoch 8/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5917 - acc: 0.4818 - val_loss: 1.5501 - val_acc: 0.5257\n",
      "Epoch 9/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5795 - acc: 0.4896 - val_loss: 1.5439 - val_acc: 0.5257\n",
      "Epoch 10/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5732 - acc: 0.4977 - val_loss: 1.5383 - val_acc: 0.5257\n",
      "Epoch 11/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5634 - acc: 0.5035 - val_loss: 1.5312 - val_acc: 0.5284\n",
      "Epoch 12/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5544 - acc: 0.5054 - val_loss: 1.5438 - val_acc: 0.5298\n",
      "Epoch 13/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5466 - acc: 0.5031 - val_loss: 1.5434 - val_acc: 0.5284\n",
      "Epoch 14/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5431 - acc: 0.5089 - val_loss: 1.5339 - val_acc: 0.5326\n",
      "Epoch 15/300\n",
      "2586/2586 [==============================] - 3s - loss: 1.5328 - acc: 0.5046 - val_loss: 1.5583 - val_acc: 0.5479\n",
      "Epoch 00014: early stopping\n",
      "Score log_loss:  1.55831289234\n",
      "Start KFold number 2 from 5\n",
      "Split train:  2617 2617\n",
      "Split valid:  690 690\n",
      "Train on 2617 samples, validate on 690 samples\n",
      "Epoch 1/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.9837 - acc: 0.5166 - val_loss: 1.9819 - val_acc: 0.3159\n",
      "Epoch 2/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.7537 - acc: 0.4219 - val_loss: 1.9250 - val_acc: 0.3159\n",
      "Epoch 3/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.7073 - acc: 0.3924 - val_loss: 1.8815 - val_acc: 0.3159\n",
      "Epoch 4/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.6667 - acc: 0.4501 - val_loss: 1.8054 - val_acc: 0.3159\n",
      "Epoch 5/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.6479 - acc: 0.4776 - val_loss: 1.7213 - val_acc: 0.3159\n",
      "Epoch 6/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.6302 - acc: 0.4895 - val_loss: 1.6556 - val_acc: 0.4652\n",
      "Epoch 7/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.6146 - acc: 0.5090 - val_loss: 1.6157 - val_acc: 0.5609\n",
      "Epoch 8/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.6029 - acc: 0.5128 - val_loss: 1.5828 - val_acc: 0.5246\n",
      "Epoch 9/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5874 - acc: 0.5174 - val_loss: 1.5663 - val_acc: 0.5188\n",
      "Epoch 10/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5848 - acc: 0.5212 - val_loss: 1.5613 - val_acc: 0.5101\n",
      "Epoch 11/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5745 - acc: 0.5197 - val_loss: 1.5622 - val_acc: 0.5072\n",
      "Epoch 12/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5701 - acc: 0.5212 - val_loss: 1.5579 - val_acc: 0.5014\n",
      "Epoch 13/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5630 - acc: 0.5258 - val_loss: 1.5564 - val_acc: 0.5014\n",
      "Epoch 14/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5568 - acc: 0.5239 - val_loss: 1.5738 - val_acc: 0.5029\n",
      "Epoch 15/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5455 - acc: 0.5269 - val_loss: 1.5693 - val_acc: 0.5014\n",
      "Epoch 16/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5431 - acc: 0.5288 - val_loss: 1.5707 - val_acc: 0.5000\n",
      "Epoch 17/300\n",
      "2617/2617 [==============================] - 3s - loss: 1.5419 - acc: 0.5281 - val_loss: 1.5799 - val_acc: 0.5000\n",
      "Epoch 00016: early stopping\n",
      "Score log_loss:  1.57989520651\n",
      "Start KFold number 3 from 5\n",
      "Split train:  2630 2630\n",
      "Split valid:  677 677\n",
      "Train on 2630 samples, validate on 677 samples\n",
      "Epoch 1/300\n",
      "2630/2630 [==============================] - 3s - loss: 2.0337 - acc: 0.4487 - val_loss: 2.0100 - val_acc: 0.2009\n",
      "Epoch 2/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.7976 - acc: 0.3133 - val_loss: 1.9880 - val_acc: 0.2009\n",
      "Epoch 3/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.7441 - acc: 0.3133 - val_loss: 1.9488 - val_acc: 0.2009\n",
      "Epoch 4/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.7114 - acc: 0.3361 - val_loss: 1.8732 - val_acc: 0.2009\n",
      "Epoch 5/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6842 - acc: 0.3529 - val_loss: 1.7736 - val_acc: 0.2393\n",
      "Epoch 6/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6632 - acc: 0.3814 - val_loss: 1.6955 - val_acc: 0.5214\n",
      "Epoch 7/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6467 - acc: 0.4038 - val_loss: 1.6451 - val_acc: 0.5480\n",
      "Epoch 8/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6385 - acc: 0.4087 - val_loss: 1.6138 - val_acc: 0.5702\n",
      "Epoch 9/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6221 - acc: 0.4361 - val_loss: 1.5985 - val_acc: 0.5908\n",
      "Epoch 10/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6189 - acc: 0.4308 - val_loss: 1.5937 - val_acc: 0.5805\n",
      "Epoch 11/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.6087 - acc: 0.4452 - val_loss: 1.5837 - val_acc: 0.5953\n",
      "Epoch 12/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.5960 - acc: 0.4559 - val_loss: 1.5890 - val_acc: 0.5879\n",
      "Epoch 13/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.5928 - acc: 0.4570 - val_loss: 1.5954 - val_acc: 0.5790\n",
      "Epoch 14/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.5896 - acc: 0.4643 - val_loss: 1.5899 - val_acc: 0.5894\n",
      "Epoch 15/300\n",
      "2630/2630 [==============================] - 3s - loss: 1.5831 - acc: 0.4616 - val_loss: 1.5879 - val_acc: 0.5982\n",
      "Epoch 00014: early stopping\n",
      "Score log_loss:  1.58789547948\n",
      "Start KFold number 4 from 5\n",
      "Split train:  2654 2654\n",
      "Split valid:  653 653\n",
      "Train on 2654 samples, validate on 653 samples\n",
      "Epoch 1/300\n",
      "2654/2654 [==============================] - 3s - loss: 2.0630 - acc: 0.4563 - val_loss: 1.9920 - val_acc: 0.1838\n",
      "Epoch 2/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.7005 - acc: 0.3975 - val_loss: 1.9782 - val_acc: 0.1838\n",
      "Epoch 3/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.6566 - acc: 0.3493 - val_loss: 1.9424 - val_acc: 0.1838\n",
      "Epoch 4/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.6154 - acc: 0.3821 - val_loss: 1.8663 - val_acc: 0.1838\n",
      "Epoch 5/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5895 - acc: 0.4096 - val_loss: 1.7919 - val_acc: 0.1838\n",
      "Epoch 6/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5694 - acc: 0.4446 - val_loss: 1.7450 - val_acc: 0.1838\n",
      "Epoch 7/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5549 - acc: 0.4586 - val_loss: 1.7147 - val_acc: 0.1853\n",
      "Epoch 8/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5409 - acc: 0.4729 - val_loss: 1.6967 - val_acc: 0.3706\n",
      "Epoch 9/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5293 - acc: 0.4898 - val_loss: 1.6882 - val_acc: 0.4242\n",
      "Epoch 10/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5192 - acc: 0.4962 - val_loss: 1.6870 - val_acc: 0.4273\n",
      "Epoch 11/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5073 - acc: 0.5015 - val_loss: 1.6817 - val_acc: 0.4487\n",
      "Epoch 12/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.5014 - acc: 0.5064 - val_loss: 1.6810 - val_acc: 0.4456\n",
      "Epoch 13/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.4973 - acc: 0.5083 - val_loss: 1.6856 - val_acc: 0.4319\n",
      "Epoch 14/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.4895 - acc: 0.5109 - val_loss: 1.6878 - val_acc: 0.3997\n",
      "Epoch 15/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.4827 - acc: 0.5132 - val_loss: 1.6928 - val_acc: 0.4104\n",
      "Epoch 16/300\n",
      "2654/2654 [==============================] - 3s - loss: 1.4699 - acc: 0.5154 - val_loss: 1.6909 - val_acc: 0.3905\n",
      "Epoch 00015: early stopping\n",
      "Score log_loss:  1.69086794065\n",
      "Start KFold number 5 from 5\n",
      "Split train:  2741 2741\n",
      "Split valid:  566 566\n",
      "Train on 2741 samples, validate on 566 samples\n",
      "Epoch 1/300\n",
      "2741/2741 [==============================] - 3s - loss: 2.0564 - acc: 0.4436 - val_loss: 2.0633 - val_acc: 0.1643\n",
      "Epoch 2/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.7713 - acc: 0.3269 - val_loss: 2.0270 - val_acc: 0.1643\n",
      "Epoch 3/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.7138 - acc: 0.3185 - val_loss: 1.9916 - val_acc: 0.1643\n",
      "Epoch 4/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.6807 - acc: 0.3415 - val_loss: 1.8781 - val_acc: 0.1643\n",
      "Epoch 5/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.6535 - acc: 0.3605 - val_loss: 1.7896 - val_acc: 0.1643\n",
      "Epoch 6/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.6314 - acc: 0.3893 - val_loss: 1.7105 - val_acc: 0.1643\n",
      "Epoch 7/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.6210 - acc: 0.4130 - val_loss: 1.6768 - val_acc: 0.1643\n",
      "Epoch 8/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.6055 - acc: 0.4185 - val_loss: 1.6322 - val_acc: 0.1820\n",
      "Epoch 9/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5931 - acc: 0.4433 - val_loss: 1.6286 - val_acc: 0.2155\n",
      "Epoch 10/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5854 - acc: 0.4429 - val_loss: 1.6333 - val_acc: 0.4399\n",
      "Epoch 11/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5805 - acc: 0.4480 - val_loss: 1.6121 - val_acc: 0.4982\n",
      "Epoch 12/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5653 - acc: 0.4575 - val_loss: 1.6266 - val_acc: 0.5177\n",
      "Epoch 13/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5639 - acc: 0.4684 - val_loss: 1.6167 - val_acc: 0.5389\n",
      "Epoch 14/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5553 - acc: 0.4666 - val_loss: 1.6135 - val_acc: 0.5283\n",
      "Epoch 15/300\n",
      "2741/2741 [==============================] - 3s - loss: 1.5490 - acc: 0.4677 - val_loss: 1.6482 - val_acc: 0.5265\n",
      "Epoch 00014: early stopping\n",
      "Score log_loss:  1.64818165401\n",
      "Log_loss train independent avg:  0.183859902048\n",
      "Start KFold number 1 from 5\n",
      "Test shape: (694, 3, 256, 256)\n",
      "694 test samples\n",
      "Read and process test data time: 4.13 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected batchnormalization_input_1 to have shape (None, 512, 16, 16) but got array with shape (694, 3, 256, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9846b6872ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minfo_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_cross_validation_create_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrun_cross_validation_process_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-491980ea14f5>\u001b[0m in \u001b[0;36mrun_cross_validation_process_test\u001b[0;34m(info_string, models)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start KFold number {} from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_normalize_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0myfull_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[1;32m   1253\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                                    check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected batchnormalization_input_1 to have shape (None, 512, 16, 16) but got array with shape (694, 3, 256, 256)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Keras version: {}'.format(keras_version))\n",
    "    num_folds = 5\n",
    "    info_string, models = run_cross_validation_create_models(num_folds)\n",
    "    run_cross_validation_process_test(info_string, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
