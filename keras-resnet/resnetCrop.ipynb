{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "import resnet\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/fish/scripts')\n",
    "# Read in Libraries\n",
    "from __future__ import division, print_function\n",
    "from logbook import Logger, StreamHandler\n",
    "import sys\n",
    "StreamHandler(sys.stdout).push_application()\n",
    "log = Logger('Logbook')\n",
    "import shutil, csv, time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "import ujson as json\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import gc\n",
    "# from __future__ import division, print_function\n",
    "from theano.sandbox import cuda\n",
    "from vgg16bn import Vgg16BN\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "def accuracyfunc(y_act, y_pred):\n",
    "    return metrics.accuracy_score(np.argmax(y_act, axis=1), np.argmax(y_pred, axis=1))\n",
    "    \n",
    "def refresh_directory_structure(name, sub_dirs):\n",
    "    gdir = os.path.join(path, name)\n",
    "    if os.path.exists(gdir):\n",
    "        shutil.rmtree(gdir)\n",
    "    os.makedirs(gdir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        os.makedirs(os.path.join(gdir, sub_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=.5, cooldown=0, patience=5, min_lr=0.5e-7)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('resnet18_cropped_fish.csv')\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 8 # 10\n",
    "nb_epoch = 200\n",
    "data_augmentation = False\n",
    "path = \"../data/fish/relabel/\"\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 250, 250\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3070 images belonging to 8 classes.\n",
      "Found 689 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "trn = get_data(path+'train', (img_rows, img_cols))\n",
    "val = get_data(path+'valid', (img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3070, 3, 250, 250)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3070 images belonging to 8 classes.\n",
      "Found 689 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "(val_classes, trn_classes, val_labels, trn_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = trn.astype('float32')  # X_train.astype('float32')\n",
    "X_test =  val.astype('float32')  # X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = trn_labels\n",
    "Y_test  = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = resnet.ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "#model.optimizer.lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 3070 samples, validate on 689 samples\n",
      "Epoch 1/200\n",
      "3070/3070 [==============================] - 194s - loss: 5.6977 - acc: 0.6746 - val_loss: 8.9092 - val_acc: 0.1567\n",
      "Epoch 2/200\n",
      "3070/3070 [==============================] - 193s - loss: 3.8062 - acc: 0.8827 - val_loss: 4.5755 - val_acc: 0.5210\n",
      "Epoch 3/200\n",
      "3070/3070 [==============================] - 191s - loss: 2.7793 - acc: 0.9482 - val_loss: 5.1255 - val_acc: 0.5022\n",
      "Epoch 4/200\n",
      "3070/3070 [==============================] - 191s - loss: 2.2720 - acc: 0.9397 - val_loss: 4.1277 - val_acc: 0.4136\n",
      "Epoch 5/200\n",
      "3070/3070 [==============================] - 192s - loss: 1.8623 - acc: 0.9700 - val_loss: 3.6490 - val_acc: 0.5269\n",
      "Epoch 6/200\n",
      "3070/3070 [==============================] - 192s - loss: 1.5678 - acc: 0.9818 - val_loss: 3.2906 - val_acc: 0.5283\n",
      "Epoch 7/200\n",
      "3070/3070 [==============================] - 193s - loss: 1.3574 - acc: 0.9860 - val_loss: 3.0766 - val_acc: 0.6081\n",
      "Epoch 8/200\n",
      "3070/3070 [==============================] - 193s - loss: 1.2054 - acc: 0.9844 - val_loss: 3.4773 - val_acc: 0.5036\n",
      "Epoch 9/200\n",
      "3070/3070 [==============================] - 191s - loss: 1.1907 - acc: 0.9583 - val_loss: 4.7020 - val_acc: 0.4993\n",
      "Epoch 10/200\n",
      "3070/3070 [==============================] - 194s - loss: 1.1565 - acc: 0.9544 - val_loss: 3.5811 - val_acc: 0.5138\n",
      "Epoch 11/200\n",
      "3070/3070 [==============================] - 191s - loss: 1.0047 - acc: 0.9805 - val_loss: 3.3330 - val_acc: 0.5370\n",
      "Epoch 12/200\n",
      "3070/3070 [==============================] - 192s - loss: 0.8948 - acc: 0.9902 - val_loss: 2.8276 - val_acc: 0.6023\n",
      "Epoch 13/200\n",
      "3070/3070 [==============================] - 191s - loss: 0.8081 - acc: 0.9954 - val_loss: 2.3640 - val_acc: 0.5878\n",
      "Epoch 14/200\n",
      "3070/3070 [==============================] - 190s - loss: 0.7638 - acc: 0.9902 - val_loss: 3.6219 - val_acc: 0.4151\n",
      "Epoch 15/200\n",
      "3070/3070 [==============================] - 193s - loss: 0.7501 - acc: 0.9853 - val_loss: 4.1292 - val_acc: 0.5283\n",
      "Epoch 16/200\n",
      "3070/3070 [==============================] - 193s - loss: 0.8428 - acc: 0.9544 - val_loss: 9.6083 - val_acc: 0.2627\n",
      "Epoch 17/200\n",
      "3070/3070 [==============================] - 191s - loss: 0.8043 - acc: 0.9684 - val_loss: 6.8181 - val_acc: 0.2975\n",
      "Epoch 18/200\n",
      "3070/3070 [==============================] - 190s - loss: 0.7211 - acc: 0.9824 - val_loss: 4.0597 - val_acc: 0.4354\n",
      "Epoch 19/200\n",
      "3070/3070 [==============================] - 193s - loss: 0.6618 - acc: 0.9889 - val_loss: 2.5825 - val_acc: 0.5646\n",
      "Epoch 20/200\n",
      "3070/3070 [==============================] - 195s - loss: 0.6096 - acc: 0.9971 - val_loss: 2.5826 - val_acc: 0.6357\n",
      "Epoch 21/200\n",
      "3070/3070 [==============================] - 193s - loss: 0.5823 - acc: 1.0000 - val_loss: 2.6741 - val_acc: 0.6459\n",
      "Epoch 22/200\n",
      "3070/3070 [==============================] - 193s - loss: 0.5663 - acc: 0.9997 - val_loss: 2.6646 - val_acc: 0.6473\n",
      "Epoch 23/200\n",
      "3070/3070 [==============================] - 192s - loss: 0.5509 - acc: 0.9997 - val_loss: 2.6728 - val_acc: 0.6444\n",
      "Epoch 24/200\n",
      "3070/3070 [==============================] - 191s - loss: 0.5364 - acc: 0.9997 - val_loss: 2.6241 - val_acc: 0.6444\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger]) # \n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        nb_epoch=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
