{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Read in Libraries\n",
    "from __future__ import division, print_function\n",
    "from logbook import Logger, StreamHandler\n",
    "import sys\n",
    "StreamHandler(sys.stdout).push_application()\n",
    "log = Logger('Logbook')\n",
    "import shutil, csv, time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "import ujson as json\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import gc\n",
    "# from __future__ import division, print_function\n",
    "from theano.sandbox import cuda\n",
    "from vgg16bn import Vgg16BN\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "def accuracyfunc(y_act, y_pred):\n",
    "    return metrics.accuracy_score(np.argmax(y_act, axis=1), np.argmax(y_pred, axis=1))\n",
    "    \n",
    "def refresh_directory_structure(name, sub_dirs):\n",
    "    gdir = os.path.join(path, name)\n",
    "    if os.path.exists(gdir):\n",
    "        shutil.rmtree(gdir)\n",
    "    os.makedirs(gdir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        os.makedirs(os.path.join(gdir, sub_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-02-19 19:06:10.369443] INFO: Logbook: Set Paramters\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters and check files\n",
    "refresh_directories = False\n",
    "input_exists = True\n",
    "full = True\n",
    "log.info('Set Paramters')\n",
    "path = \"../data/fish/\"\n",
    "batch_size=32\n",
    "clip = 0.99\n",
    "bags = 1\n",
    "load_size = (440, 780)#(360, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the test and valid directory\n",
    "if refresh_directories:\n",
    "    log.info('Create directory structure and validation files')\n",
    "    sub_dirs = os.listdir(os.path.join(path, 'train-all'))\n",
    "    if '.DS_Store' in sub_dirs: sub_dirs.remove('.DS_Store')\n",
    "    refresh_directory_structure('train', sub_dirs)\n",
    "    refresh_directory_structure('valid', sub_dirs)\n",
    "    for c,row in enumerate(csv.DictReader(open('../image_validation_set.csv'))):\n",
    "        value = 'valid' if row['Validation'] == '1' else 'train'\n",
    "        name_from = os.path.join(path, 'train-all', row['SubDirectory'], row['file_name'])\n",
    "        name_to   = os.path.join(path, value, row['SubDirectory'], row['file_name'])\n",
    "        shutil.copyfile(name_from, name_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-02-19 19:07:02.129702] INFO: Logbook: Get VGG\n",
      "[2017-02-19 19:07:05.420238] INFO: Logbook: Create VGG\n",
      "Found 3086 images belonging to 8 classes.\n",
      "Found 691 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "[2017-02-19 19:07:06.147404] INFO: Logbook: Read filenames\n"
     ]
    }
   ],
   "source": [
    "# Read in our VGG pretrained model\n",
    "log.info('Get VGG')\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "# Create our VGG model\n",
    "log.info('Create VGG')\n",
    "vgg640 = Vgg16BN(load_size).model\n",
    "vgg640.pop()\n",
    "vgg640.input_shape, vgg640.output_shape\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# get labels\n",
    "(val_classes, trn_classes, val_labels, trn_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)\n",
    "\n",
    "# Read in filenames\n",
    "log.info('Read filenames')\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the boxes\n",
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "for c in anno_classes:\n",
    "    j = json.load(open(os.path.join(path, 'box/{}_labels.json'.format(c)), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]\n",
    "\n",
    "# make it easy to find the nof dots, by putting themin the middle\n",
    "#empty_bbox = {'height': 0., 'width': 0., 'x': 1280/2., 'y': 720/2}\n",
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "\n",
    "# Finally, we convert the dictionary into an array, and convert the coordinates to our resized 224x224 images.\n",
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    conv_x = (load_size[1] / size[0])#(224. / size[0])\n",
    "    conv_y = (load_size[0] / size[1])#(224. / size[1])\n",
    "    bb[0] = bb[0]*conv_y\n",
    "    bb[1] = bb[1]*conv_x\n",
    "    bb[2] = max(bb[2]*conv_x, 0)\n",
    "    bb[3] = max(bb[3]*conv_y, 0)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_sizes = [PIL.Image.open(path+'train/'+f).size for f in filenames]\n",
    "val_sizes = [PIL.Image.open(path+'valid/'+f).size for f in val_filenames]\n",
    "tst_sizes = [PIL.Image.open(path+'test/'+f).size for f in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_bbox = np.stack([convert_bb(bb_json[f], s) for f,s in zip(raw_filenames, trn_sizes)], \n",
    "                   ).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, val_sizes)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 691 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = val_bbox[i]\n",
    "    plot(val[i])\n",
    "    plt.gca().add_patch(create_rect(bb))\n",
    "\n",
    "val = get_data(path+'valid', load_size)\n",
    "show_bb(500)\n",
    "del val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log.info('Read in data')\n",
    "if not input_exists:\n",
    "\n",
    "    batches = get_batches(path+'train', batch_size=batch_size)\n",
    "    val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "    (val_classes, trn_classes, val_labels, trn_labels, \n",
    "        val_filenames, filenames, test_filenames) = get_classes(path)\n",
    "    \n",
    "    # Fetch our large images \n",
    "    # Precompute the output of the convolutional part of VGG\n",
    "    log.info('Fetch images')\n",
    "    log.info('Get VGG output')\n",
    "    log.info('Write VGG output')\n",
    "    \n",
    "    val = get_data(path+'valid', load_size)\n",
    "    conv_val_feat = vgg640.predict(val, batch_size=16, verbose=1)\n",
    "    save_array(path+'results/conv_val_big_feat.dat', conv_val_feat)\n",
    "    del val, conv_val_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    trn = get_data(path+'train', load_size)\n",
    "    conv_trn_feat = vgg640.predict(trn, batch_size=16, verbose=1)    \n",
    "    del trn\n",
    "    gc.collect()\n",
    "    save_array(path+'results/conv_trn_big_feat.dat', conv_trn_feat) \n",
    "    del conv_trn_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    test = get_data(path+'test', load_size)\n",
    "    conv_test_feat = vgg640.predict(test, batch_size=16, verbose=1)\n",
    "    save_array(path+'results/conv_test_big_feat.dat', conv_test_feat)     \n",
    "    del test, conv_test_feat\n",
    "    gc.collect()\n",
    "\n",
    "    # For memory purposes delete out the original train and validation\n",
    "    log.info('Clear up memory')\n",
    "    #del trn, val, test\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
