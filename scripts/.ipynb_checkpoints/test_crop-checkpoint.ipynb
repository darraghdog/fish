{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in Libraries\n",
    "from __future__ import division, print_function\n",
    "from logbook import Logger, StreamHandler\n",
    "import sys\n",
    "StreamHandler(sys.stdout).push_application()\n",
    "log = Logger('Logbook')\n",
    "import shutil, csv, time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "import ujson as json\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import gc\n",
    "# from __future__ import division, print_function\n",
    "from theano.sandbox import cuda\n",
    "from vgg16bn import Vgg16BN\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "def accuracyfunc(y_act, y_pred):\n",
    "    return metrics.accuracy_score(np.argmax(y_act, axis=1), np.argmax(y_pred, axis=1))\n",
    "    \n",
    "def refresh_directory_structure(name, sub_dirs):\n",
    "    gdir = os.path.join(path, name)\n",
    "    if os.path.exists(gdir):\n",
    "        shutil.rmtree(gdir)\n",
    "    os.makedirs(gdir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        os.makedirs(os.path.join(gdir, sub_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-10 23:34:55.045758] INFO: Logbook: Set Paramters\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters and check files\n",
    "refresh_directories = False\n",
    "input_exists = True\n",
    "full = False\n",
    "log.info('Set Paramters')\n",
    "path = \"../data/fish/crop/\"\n",
    "batch_size=32\n",
    "clip = 0.99\n",
    "bags = 1\n",
    "load_size = (300,300) #(360, 640)\n",
    "aug_batches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-10 23:34:55.058683] INFO: Logbook: Get VGG\n",
      "[2017-03-10 23:34:58.133834] INFO: Logbook: Create VGG\n",
      "Found 2685 images belonging to 8 classes.\n",
      "Found 622 images belonging to 8 classes.\n",
      "Found 694 images belonging to 1 classes.\n",
      "[2017-03-10 23:34:58.651447] INFO: Logbook: Read filenames\n"
     ]
    }
   ],
   "source": [
    "# Read in our VGG pretrained model\n",
    "log.info('Get VGG')\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "# Create our VGG model\n",
    "log.info('Create VGG')\n",
    "vgg640 = Vgg16BN(load_size).model\n",
    "vgg640.pop()\n",
    "vgg640.input_shape, vgg640.output_shape\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# get labels\n",
    "(val_classes, trn_classes, val_labels, trn_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)\n",
    "\n",
    "# Read in filenames\n",
    "log.info('Read filenames')\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 622 images belonging to 8 classes.\n",
      "Found 2685 images belonging to 8 classes.\n",
      "Found 694 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72913"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=180, height_shift_range=0.05, horizontal_flip=True,\n",
    "                                 # zoom_range=0.2,\n",
    "                shear_range=0.05, channel_shift_range=20, width_shift_range=0.05)\n",
    "da_val_batches = get_batches(path+'valid', gen_t, batch_size=batch_size, shuffle=False, target_size=load_size)\n",
    "da_trn_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False, target_size=load_size)\n",
    "da_tst_batches = get_batches(path+'test', gen_t, batch_size=batch_size, shuffle=False, target_size=load_size)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-10 23:34:59.428119] INFO: Logbook: Read in data\n"
     ]
    }
   ],
   "source": [
    "log.info('Read in data')\n",
    "if not input_exists:\n",
    "    \n",
    "    # Fetch our large images \n",
    "    # Precompute the output of the convolutional part of VGG\n",
    "    log.info('Fetch images')\n",
    "    log.info('Get VGG output')\n",
    "    log.info('Write VGG output')\n",
    "    \n",
    "    #log.info('Save Val Weights')\n",
    "    da_conv_val_feat = vgg640.predict_generator(da_val_batches, da_val_batches.nb_sample*aug_batches)\n",
    "    save_array(path+'../results/da_conv_val_feat.dat', da_conv_val_feat)\n",
    "    del da_conv_val_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    #log.info('Save Trn Weights')\n",
    "    da_conv_trn_feat = vgg640.predict_generator(da_trn_batches, da_trn_batches.nb_sample*aug_batches)\n",
    "    save_array(path+'../results/da_conv_trn_feat.dat', da_conv_trn_feat)\n",
    "    del da_conv_trn_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    val = get_data(path+'valid', load_size)\n",
    "    conv_val_feat = vgg640.predict(val, batch_size=16, verbose=1)\n",
    "    save_array(path+'../results/dano_conv_val_feat.dat', conv_val_feat)\n",
    "    del val, conv_val_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    test = get_data(path+'test', load_size)\n",
    "    conv_test_feat = vgg640.predict(test, batch_size=16, verbose=1)\n",
    "    save_array(path+'../results/dano_conv_test_feat.dat', conv_test_feat)     \n",
    "    del test, conv_test_feat\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    trn = get_data(path+'train', load_size)\n",
    "    conv_trn_feat = vgg640.predict(trn, batch_size=16, verbose=1)    \n",
    "    del trn\n",
    "    gc.collect()\n",
    "    save_array(path+'../results/dano_conv_trn_feat.dat', conv_trn_feat) \n",
    "    del conv_trn_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    # For memory purposes delete out the original train and validation\n",
    "    log.info('Clear up memory')\n",
    "    #del trn, val, test\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's include the real training data as well in its non-augmented form.\n",
    "da_conv_trn_feat = load_array(path+'../results/da_conv_trn_feat.dat')\n",
    "dano_conv_trn_feat = load_array(path+'../results/dano_conv_trn_feat.dat')\n",
    "gc.collect()\n",
    "da_conv_trn_feat = np.concatenate([da_conv_trn_feat, dano_conv_trn_feat])\n",
    "del dano_conv_trn_feat \n",
    "gc.collect()\n",
    "\n",
    "# Validation set shouldonly be augmented for a full run\n",
    "da_conv_val_feat = load_array(path+'../results/dano_conv_val_feat.dat')\n",
    "if full:\n",
    "    dano_conv_val_feat = load_array(path+'../results/da_conv_val_feat.dat')\n",
    "    da_conv_val_feat = np.concatenate([da_conv_val_feat, dano_conv_val_feat])\n",
    "    del dano_conv_val_feat \n",
    "    gc.collect()\n",
    "\n",
    "conv_test_feat = load_array(path+'../results/dano_conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we've now got a dataset 3x bigger than before, we'll need to copy our labels 6 times too.\n",
    "da_trn_labels = np.concatenate([trn_labels]*(aug_batches + 1))\n",
    "#da_trn_bbox = np.concatenate([trn_bbox]*(aug_batches + 1))\n",
    "\n",
    "# Validation set shouldonly be augmented for a full run\n",
    "if full:\n",
    "    da_val_labels = np.concatenate([val_labels]*(aug_batches + 1))\n",
    "    #da_val_bbox = np.concatenate([val_bbox]*(aug_batches + 1))\n",
    "else:\n",
    "    da_val_labels = val_labels\n",
    "    #da_val_bbox = val_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "def fish_only(mat):\n",
    "    return np.delete(mat, 4, axis=1)\n",
    "\n",
    "trn_of_labels = fish_only(da_trn_labels)\n",
    "val_of_labels = fish_only(da_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-10 23:35:17.267754] INFO: Logbook: Create and fit CNN\n"
     ]
    }
   ],
   "source": [
    "if full:\n",
    "    da_conv_trn_feat = np.concatenate([da_conv_trn_feat, da_conv_val_feat])\n",
    "    trn_of_labels = np.concatenate([trn_of_labels, val_of_labels]) \n",
    "    #trn_bbox = np.concatenate([trn_bbox, val_bbox])\n",
    "    \n",
    "# Our Convolutional Net Architecture\n",
    "log.info('Create and fit CNN')\n",
    "p=0.6\n",
    "# Set up the fully convolutional net (FCN); \n",
    "conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "nf=128; p=0. # No dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 18, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.0287 - acc: 0.6897 - val_loss: 0.4122 - val_acc: 0.8736\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5351 - acc: 0.8181 - val_loss: 0.3027 - val_acc: 0.9264\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3631 - acc: 0.8764 - val_loss: 0.2199 - val_acc: 0.9566\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2230 - acc: 0.9262 - val_loss: 0.1066 - val_acc: 0.9862\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1563 - acc: 0.9473 - val_loss: 0.0901 - val_acc: 0.9884\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0996 - acc: 0.9675 - val_loss: 0.0687 - val_acc: 0.9920\n",
      "[2017-03-10 23:38:17.184402] INFO: Logbook: Bagged Validation Logloss 0.069\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0831 - acc: 0.9717 - val_loss: 0.0684 - val_acc: 0.9868\n",
      "[2017-03-10 23:38:48.039072] INFO: Logbook: Bagged Validation Logloss 0.065\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0606 - acc: 0.9793 - val_loss: 0.0193 - val_acc: 0.9984\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0515 - acc: 0.9834 - val_loss: 0.0656 - val_acc: 0.9852\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0476 - acc: 0.9845 - val_loss: 0.0139 - val_acc: 0.9994\n",
      "[2017-03-10 23:40:15.006679] INFO: Logbook: Bagged Validation Logloss 0.046\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0563 - acc: 0.9814 - val_loss: 0.0096 - val_acc: 0.9997\n",
      "[2017-03-10 23:40:45.759452] INFO: Logbook: Bagged Validation Logloss 0.036\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0204 - val_acc: 0.9971\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0368 - acc: 0.9881 - val_loss: 0.0166 - val_acc: 0.9968\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "[2017-03-10 23:42:12.771907] INFO: Logbook: Bagged Validation Logloss 0.029\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0288 - acc: 0.9896 - val_loss: 0.0054 - val_acc: 0.9997\n",
      "[2017-03-10 23:42:43.554011] INFO: Logbook: Bagged Validation Logloss 0.025\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.1193 - acc: 0.6647 - val_loss: 0.5428 - val_acc: 0.8280\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5930 - acc: 0.8002 - val_loss: 0.2767 - val_acc: 0.9415\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3978 - acc: 0.8669 - val_loss: 0.2165 - val_acc: 0.9608\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2655 - acc: 0.9099 - val_loss: 0.1673 - val_acc: 0.9675\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1870 - acc: 0.9378 - val_loss: 0.1090 - val_acc: 0.9830\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1367 - acc: 0.9543 - val_loss: 0.0721 - val_acc: 0.9875\n",
      "[2017-03-10 23:45:43.325542] INFO: Logbook: Bagged Validation Logloss 0.030\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0981 - acc: 0.9676 - val_loss: 0.0533 - val_acc: 0.9961\n",
      "[2017-03-10 23:46:14.182338] INFO: Logbook: Bagged Validation Logloss 0.033\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0639 - acc: 0.9802 - val_loss: 0.0358 - val_acc: 0.9974\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0588 - acc: 0.9809 - val_loss: 0.0383 - val_acc: 0.9949\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0542 - acc: 0.9813 - val_loss: 0.0165 - val_acc: 0.9997\n",
      "[2017-03-10 23:47:41.172294] INFO: Logbook: Bagged Validation Logloss 0.031\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0439 - acc: 0.9865 - val_loss: 0.0188 - val_acc: 0.9990\n",
      "[2017-03-10 23:48:12.091718] INFO: Logbook: Bagged Validation Logloss 0.029\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0386 - acc: 0.9884 - val_loss: 0.0204 - val_acc: 0.9971\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0355 - acc: 0.9891 - val_loss: 0.0111 - val_acc: 0.9987\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0328 - acc: 0.9892 - val_loss: 0.0076 - val_acc: 0.9990\n",
      "[2017-03-10 23:49:39.118669] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0402 - acc: 0.9865 - val_loss: 0.0172 - val_acc: 0.9971\n",
      "[2017-03-10 23:50:09.918867] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.1430 - acc: 0.6705 - val_loss: 0.4841 - val_acc: 0.8489\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5740 - acc: 0.8182 - val_loss: 0.2632 - val_acc: 0.9514\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3914 - acc: 0.8739 - val_loss: 0.1997 - val_acc: 0.9569\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2624 - acc: 0.9161 - val_loss: 0.1343 - val_acc: 0.9785\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1682 - acc: 0.9438 - val_loss: 0.0944 - val_acc: 0.9862\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1144 - acc: 0.9633 - val_loss: 0.0695 - val_acc: 0.9900\n",
      "[2017-03-10 23:53:09.459116] INFO: Logbook: Bagged Validation Logloss 0.029\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0898 - acc: 0.9707 - val_loss: 0.0426 - val_acc: 0.9961\n",
      "[2017-03-10 23:53:40.267511] INFO: Logbook: Bagged Validation Logloss 0.029\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0699 - acc: 0.9779 - val_loss: 0.0277 - val_acc: 0.9981\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0586 - acc: 0.9814 - val_loss: 0.0373 - val_acc: 0.9939\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0572 - acc: 0.9823 - val_loss: 0.0268 - val_acc: 0.9965\n",
      "[2017-03-10 23:55:07.320343] INFO: Logbook: Bagged Validation Logloss 0.029\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 29s - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0273 - val_acc: 0.9981\n",
      "[2017-03-10 23:55:39.230981] INFO: Logbook: Bagged Validation Logloss 0.028\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0425 - acc: 0.9864 - val_loss: 0.0134 - val_acc: 0.9984\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0141 - val_acc: 0.9987\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0380 - acc: 0.9876 - val_loss: 0.0064 - val_acc: 0.9990\n",
      "[2017-03-10 23:57:06.307779] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0387 - acc: 0.9889 - val_loss: 0.0122 - val_acc: 0.9981\n",
      "[2017-03-10 23:57:37.164923] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.2202 - acc: 0.6640 - val_loss: 0.4936 - val_acc: 0.8514\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.6060 - acc: 0.8045 - val_loss: 0.2790 - val_acc: 0.9424\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.4239 - acc: 0.8599 - val_loss: 0.1912 - val_acc: 0.9736\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2611 - acc: 0.9119 - val_loss: 0.1293 - val_acc: 0.9833\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1627 - acc: 0.9479 - val_loss: 0.0818 - val_acc: 0.9884\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1252 - acc: 0.9590 - val_loss: 0.0423 - val_acc: 0.9965\n",
      "[2017-03-11 00:00:36.687277] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0946 - acc: 0.9679 - val_loss: 0.0540 - val_acc: 0.9910\n",
      "[2017-03-11 00:01:07.510635] INFO: Logbook: Bagged Validation Logloss 0.028\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0423 - val_acc: 0.9955\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0543 - acc: 0.9834 - val_loss: 0.0159 - val_acc: 0.9997\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0526 - acc: 0.9848 - val_loss: 0.0117 - val_acc: 0.9997\n",
      "[2017-03-11 00:02:34.464313] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0359 - acc: 0.9906 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "[2017-03-11 00:03:05.272358] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0413 - acc: 0.9858 - val_loss: 0.0068 - val_acc: 0.9997\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0456 - acc: 0.9855 - val_loss: 0.0146 - val_acc: 0.9990\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0407 - acc: 0.9873 - val_loss: 0.0134 - val_acc: 0.9981\n",
      "[2017-03-11 00:04:32.365814] INFO: Logbook: Bagged Validation Logloss 0.025\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0347 - acc: 0.9889 - val_loss: 0.0154 - val_acc: 0.9968\n",
      "[2017-03-11 00:05:03.193239] INFO: Logbook: Bagged Validation Logloss 0.025\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.9972 - acc: 0.6881 - val_loss: 0.4349 - val_acc: 0.8640\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5582 - acc: 0.8099 - val_loss: 0.2887 - val_acc: 0.9386\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3693 - acc: 0.8717 - val_loss: 0.2383 - val_acc: 0.9360\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2413 - acc: 0.9170 - val_loss: 0.1518 - val_acc: 0.9643\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1623 - acc: 0.9446 - val_loss: 0.0945 - val_acc: 0.9881\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1228 - acc: 0.9595 - val_loss: 0.0804 - val_acc: 0.9849\n",
      "[2017-03-11 00:08:03.063473] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0807 - acc: 0.9731 - val_loss: 0.0606 - val_acc: 0.9855\n",
      "[2017-03-11 00:08:33.890923] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0693 - acc: 0.9784 - val_loss: 0.0368 - val_acc: 0.9936\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0577 - acc: 0.9820 - val_loss: 0.0317 - val_acc: 0.9932\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0527 - acc: 0.9831 - val_loss: 0.0241 - val_acc: 0.9965\n",
      "[2017-03-11 00:10:01.002400] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0405 - acc: 0.9869 - val_loss: 0.0170 - val_acc: 0.9974\n",
      "[2017-03-11 00:10:31.843184] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0458 - acc: 0.9852 - val_loss: 0.0268 - val_acc: 0.9965\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0378 - acc: 0.9877 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0419 - acc: 0.9865 - val_loss: 0.0179 - val_acc: 0.9977\n",
      "[2017-03-11 00:11:58.801820] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0397 - acc: 0.9876 - val_loss: 0.0123 - val_acc: 0.9981\n",
      "[2017-03-11 00:12:29.640275] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.0633 - acc: 0.6764 - val_loss: 0.4712 - val_acc: 0.8489\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5582 - acc: 0.8074 - val_loss: 0.2659 - val_acc: 0.9502\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3560 - acc: 0.8766 - val_loss: 0.2255 - val_acc: 0.9556\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2386 - acc: 0.9186 - val_loss: 0.1459 - val_acc: 0.9701\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1554 - acc: 0.9491 - val_loss: 0.1170 - val_acc: 0.9788\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1136 - acc: 0.9627 - val_loss: 0.0597 - val_acc: 0.9913\n",
      "[2017-03-11 00:15:29.606148] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0776 - acc: 0.9743 - val_loss: 0.0352 - val_acc: 0.9974\n",
      "[2017-03-11 00:16:00.489100] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0635 - acc: 0.9793 - val_loss: 0.0361 - val_acc: 0.9961\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0478 - acc: 0.9853 - val_loss: 0.0237 - val_acc: 0.9968\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0478 - acc: 0.9848 - val_loss: 0.0205 - val_acc: 0.9974\n",
      "[2017-03-11 00:17:27.560210] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0502 - acc: 0.9828 - val_loss: 0.0227 - val_acc: 0.9974\n",
      "[2017-03-11 00:17:58.427801] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0462 - acc: 0.9860 - val_loss: 0.0184 - val_acc: 0.9984\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0347 - acc: 0.9888 - val_loss: 0.0179 - val_acc: 0.9971\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0316 - acc: 0.9899 - val_loss: 0.0133 - val_acc: 0.9984\n",
      "[2017-03-11 00:19:25.382623] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0279 - acc: 0.9914 - val_loss: 0.0135 - val_acc: 0.9977\n",
      "[2017-03-11 00:19:56.206708] INFO: Logbook: Bagged Validation Logloss 0.025\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.3256 - acc: 0.6645 - val_loss: 0.5017 - val_acc: 0.8379\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5709 - acc: 0.8066 - val_loss: 0.3151 - val_acc: 0.9203\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3724 - acc: 0.8712 - val_loss: 0.2208 - val_acc: 0.9540\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2445 - acc: 0.9189 - val_loss: 0.1522 - val_acc: 0.9695\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1777 - acc: 0.9424 - val_loss: 0.1076 - val_acc: 0.9801\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1220 - acc: 0.9607 - val_loss: 0.0756 - val_acc: 0.9871\n",
      "[2017-03-11 00:22:54.986830] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0996 - acc: 0.9670 - val_loss: 0.0380 - val_acc: 0.9971\n",
      "[2017-03-11 00:23:25.843818] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0663 - acc: 0.9788 - val_loss: 0.0347 - val_acc: 0.9952\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0659 - acc: 0.9783 - val_loss: 0.0244 - val_acc: 0.9974\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0559 - acc: 0.9818 - val_loss: 0.0224 - val_acc: 0.9984\n",
      "[2017-03-11 00:24:52.804695] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0381 - acc: 0.9887 - val_loss: 0.0168 - val_acc: 0.9990\n",
      "[2017-03-11 00:25:23.609145] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0404 - acc: 0.9865 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0397 - acc: 0.9880 - val_loss: 0.0159 - val_acc: 0.9987\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0398 - acc: 0.9872 - val_loss: 0.0397 - val_acc: 0.9932\n",
      "[2017-03-11 00:26:50.603291] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0400 - acc: 0.9869 - val_loss: 0.0281 - val_acc: 0.9920\n",
      "[2017-03-11 00:27:21.489356] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.0446 - acc: 0.6809 - val_loss: 0.4063 - val_acc: 0.8791\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5505 - acc: 0.8082 - val_loss: 0.3234 - val_acc: 0.9193\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3509 - acc: 0.8786 - val_loss: 0.2552 - val_acc: 0.9318\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2259 - acc: 0.9226 - val_loss: 0.1471 - val_acc: 0.9682\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1619 - acc: 0.9444 - val_loss: 0.1209 - val_acc: 0.9746\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1040 - acc: 0.9672 - val_loss: 0.0639 - val_acc: 0.9945\n",
      "[2017-03-11 00:30:21.337456] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0876 - acc: 0.9708 - val_loss: 0.0475 - val_acc: 0.9958\n",
      "[2017-03-11 00:30:52.213208] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0673 - acc: 0.9774 - val_loss: 0.0434 - val_acc: 0.9955\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0527 - acc: 0.9831 - val_loss: 0.0300 - val_acc: 0.9981\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0410 - acc: 0.9865 - val_loss: 0.0144 - val_acc: 0.9990\n",
      "[2017-03-11 00:32:19.289586] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0530 - acc: 0.9834 - val_loss: 0.0258 - val_acc: 0.9961\n",
      "[2017-03-11 00:32:50.183795] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0414 - acc: 0.9869 - val_loss: 0.0442 - val_acc: 0.9897\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0350 - acc: 0.9892 - val_loss: 0.0131 - val_acc: 0.9997\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0285 - acc: 0.9901 - val_loss: 0.0157 - val_acc: 0.9958\n",
      "[2017-03-11 00:34:17.243409] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0461 - acc: 0.9858 - val_loss: 0.0160 - val_acc: 0.9977\n",
      "[2017-03-11 00:34:48.143625] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.0337 - acc: 0.6787 - val_loss: 0.4626 - val_acc: 0.8778\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5117 - acc: 0.8227 - val_loss: 0.2894 - val_acc: 0.9473\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3333 - acc: 0.8864 - val_loss: 0.3359 - val_acc: 0.9006\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2069 - acc: 0.9316 - val_loss: 0.1868 - val_acc: 0.9585\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1272 - acc: 0.9592 - val_loss: 0.0749 - val_acc: 0.9897\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0948 - acc: 0.9705 - val_loss: 0.0731 - val_acc: 0.9900\n",
      "[2017-03-11 00:37:48.183199] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0627 - acc: 0.9813 - val_loss: 0.0320 - val_acc: 0.9984\n",
      "[2017-03-11 00:38:18.983337] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0532 - acc: 0.9835 - val_loss: 0.0348 - val_acc: 0.9974\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0425 - acc: 0.9876 - val_loss: 0.0297 - val_acc: 0.9971\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0428 - acc: 0.9859 - val_loss: 0.0162 - val_acc: 0.9974\n",
      "[2017-03-11 00:39:45.943658] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0387 - acc: 0.9877 - val_loss: 0.0251 - val_acc: 0.9939\n",
      "[2017-03-11 00:40:16.684675] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0384 - acc: 0.9871 - val_loss: 0.0104 - val_acc: 0.9997\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0385 - acc: 0.9874 - val_loss: 0.0166 - val_acc: 0.9984\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0366 - acc: 0.9886 - val_loss: 0.0232 - val_acc: 0.9945\n",
      "[2017-03-11 00:41:43.667959] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0069 - val_acc: 0.9997\n",
      "[2017-03-11 00:42:14.490943] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "th\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/3\n",
      "16535/16535 [==============================] - 28s - loss: 1.0295 - acc: 0.6862 - val_loss: 0.4238 - val_acc: 0.8833\n",
      "Epoch 2/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.5272 - acc: 0.8212 - val_loss: 0.2457 - val_acc: 0.9566\n",
      "Epoch 3/3\n",
      "16535/16535 [==============================] - 28s - loss: 0.3458 - acc: 0.8839 - val_loss: 0.2214 - val_acc: 0.9537\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.2251 - acc: 0.9227 - val_loss: 0.1492 - val_acc: 0.9765\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.1506 - acc: 0.9500 - val_loss: 0.0821 - val_acc: 0.9916\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.1003 - acc: 0.9689 - val_loss: 0.0591 - val_acc: 0.9939\n",
      "[2017-03-11 00:45:13.076963] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0802 - acc: 0.9739 - val_loss: 0.0629 - val_acc: 0.9894\n",
      "[2017-03-11 00:45:43.948124] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0724 - acc: 0.9756 - val_loss: 0.0396 - val_acc: 0.9958\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0536 - acc: 0.9814 - val_loss: 0.0155 - val_acc: 0.9994\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0545 - acc: 0.9830 - val_loss: 0.0293 - val_acc: 0.9945\n",
      "[2017-03-11 00:47:11.024122] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0475 - acc: 0.9855 - val_loss: 0.0140 - val_acc: 0.9990\n",
      "[2017-03-11 00:47:41.875874] INFO: Logbook: Bagged Validation Logloss 0.027\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0406 - acc: 0.9871 - val_loss: 0.0217 - val_acc: 0.9968\n",
      "Epoch 2/2\n",
      "16535/16535 [==============================] - 28s - loss: 0.0380 - acc: 0.9881 - val_loss: 0.0112 - val_acc: 0.9997\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0321 - acc: 0.9897 - val_loss: 0.0225 - val_acc: 0.9955\n",
      "[2017-03-11 00:49:08.868222] INFO: Logbook: Bagged Validation Logloss 0.026\n",
      "Train on 16535 samples, validate on 3110 samples\n",
      "Epoch 1/1\n",
      "16535/16535 [==============================] - 28s - loss: 0.0272 - acc: 0.9915 - val_loss: 0.0114 - val_acc: 0.9981\n",
      "[2017-03-11 00:49:39.763558] INFO: Logbook: Bagged Validation Logloss 0.026\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    inp = Input(conv_layers[-1].output_shape[1:])\n",
    "    x = BatchNormalization(axis=1)(inp)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x =   Dropout(p)(x)\n",
    "    x = Convolution2D(nf,3,3, activation='relu', border_mode='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x =   Convolution2D(7,3,3, border_mode='same')(x)\n",
    "    x =   Dropout(p)(x)\n",
    "    x =   GlobalAveragePooling2D()(x)\n",
    "    x_class = Dense(7, activation='softmax', name='class')(x)\n",
    "    \n",
    "    \n",
    "    return inp, x_class\n",
    "\n",
    "gc.collect()\n",
    "nf = 512\n",
    "p  = 0.5\n",
    "batch_size=128\n",
    "\n",
    "model, predsls, pvalsls = [], [], []\n",
    "\n",
    "for ii in range(10):\n",
    "    inp, x_class = create_model()\n",
    "    model.append(Model([inp], [x_class]))\n",
    "    model[ii].compile(Adam(lr=1e-3), loss=['categorical_crossentropy'], metrics=['accuracy']) # , decay=1e-6\n",
    "    #model[ii].summary()\n",
    "    model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=3, \n",
    "                 validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "    \n",
    "    model[ii].optimizer.lr = 1e-4\n",
    "    model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=2, \n",
    "                 validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "    count = 0\n",
    "    while count < 2:\n",
    "        model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=1, \n",
    "                     validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "        predsls.append(model[ii].predict(conv_test_feat, batch_size=batch_size)) # or try 32 batch_size\n",
    "        pvalsls.append(model[ii].predict(da_conv_val_feat, batch_size=batch_size))\n",
    "        val_score = \"%.3f\" % metrics.log_loss(val_of_labels, sum(pvalsls)/len(pvalsls))\n",
    "        #acc_score = \"%.3f\" % accuracyfunc(val_of_labels, do_clip(sum(pvalsls)/len(pvalsls), clip))\n",
    "        log.info('Bagged Validation Logloss ' + str(val_score))\n",
    "        #log.info('Bagged Validation Accuracy ' + str(acc_score))\n",
    "        count += 1\n",
    "    \n",
    "    model[ii].optimizer.lr = 1e-5\n",
    "    model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=2, \n",
    "                 validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "    count = 0\n",
    "    while count < 2:\n",
    "        model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=1, \n",
    "                     validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "        predsls.append(model[ii].predict(conv_test_feat, batch_size=batch_size)) # or try 32 batch_size\n",
    "        pvalsls.append(model[ii].predict(da_conv_val_feat, batch_size=batch_size))\n",
    "        val_score = \"%.3f\" % metrics.log_loss(val_of_labels, sum(pvalsls)/len(pvalsls))\n",
    "        #acc_score = \"%.3f\" % accuracyfunc(val_of_labels, do_clip(sum(pvalsls)/len(pvalsls), clip))\n",
    "        log.info('Bagged Validation Logloss ' + str(val_score))\n",
    "        #log.info('Bagged Validation Accuracy ' + str(acc_score))\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "    model[ii].optimizer.lr = 1e-6\n",
    "    model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=2, \n",
    "                 validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "    count = 0\n",
    "    while count < 2:\n",
    "        model[ii].fit(da_conv_trn_feat, [trn_of_labels], batch_size=batch_size, nb_epoch=1, \n",
    "                     validation_data=(da_conv_val_feat, [val_of_labels]))\n",
    "        predsls.append(model[ii].predict(conv_test_feat, batch_size=batch_size)) # or try 32 batch_size\n",
    "        pvalsls.append(model[ii].predict(da_conv_val_feat, batch_size=batch_size))\n",
    "        val_score = \"%.3f\" % metrics.log_loss(val_of_labels, sum(pvalsls)/len(pvalsls))\n",
    "        #acc_score = \"%.3f\" % accuracyfunc(val_of_labels, do_clip(sum(pvalsls)/len(pvalsls), clip))\n",
    "        log.info('Bagged Validation Logloss ' + str(val_score))\n",
    "        #log.info('Bagged Validation Accuracy ' + str(acc_score))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-11 00:49:39.783825] INFO: Logbook: Done - files @ ../data/fish/crop/../results/subm_full_crop_of_20170310.csv\n"
     ]
    }
   ],
   "source": [
    "# metrics.log_loss(val_labels, do_clip(sum(pvalsls)/len(pvalsls), .9999))\n",
    "preds = sum(predsls)/len(predsls)\n",
    "subm = do_clip(preds, clip)\n",
    "\n",
    "if full:\n",
    "    subm_name = path+'../results/subm_full_crop_of_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = path+'../results/subm_part_crop_of_' + timestr + '.csv' #'.csv.gz'\n",
    "\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "log.info('Done - files @ ' + subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../data/fish/crop/../results/subm_full_crop_of_20170310.csv' target='_blank'>../data/fish/crop/../results/subm_full_crop_of_20170310.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/fish/data/fish/results/subm_full_crop_of_20170310.csv"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
