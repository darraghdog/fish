{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Read in Libraries\n",
    "from __future__ import division, print_function\n",
    "from logbook import Logger, StreamHandler\n",
    "import sys\n",
    "StreamHandler(sys.stdout).push_application()\n",
    "log = Logger('Logbook')\n",
    "import shutil, csv, time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "import ujson as json\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import gc\n",
    "# from __future__ import division, print_function\n",
    "from theano.sandbox import cuda\n",
    "from vgg16bn import Vgg16BN\n",
    "from sklearn import metrics\n",
    "from distutils.dir_util import copy_tree\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "def accuracyfunc(y_act, y_pred):\n",
    "    return metrics.accuracy_score(np.argmax(y_act, axis=1), np.argmax(y_pred, axis=1))\n",
    "    \n",
    "def refresh_directory_structure(name, sub_dirs):\n",
    "    gdir = os.path.join(path, name)\n",
    "    if os.path.exists(gdir):\n",
    "        shutil.rmtree(gdir)\n",
    "    os.makedirs(gdir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        os.makedirs(os.path.join(gdir, sub_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/fish/scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-20 23:09:14.546472] INFO: Logbook: Set Paramters\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters and check files\n",
    "refresh_directories = False\n",
    "input_exists = False\n",
    "full = True\n",
    "log.info('Set Paramters')\n",
    "path = \"../data/fish/\"\n",
    "batch_size=32\n",
    "clip = 0.99\n",
    "bags = 10\n",
    "load_size = (400, 700)#(440, 780)#(360, 640)\n",
    "yolo_cutoff = 0.7\n",
    "sub_cutoff = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the test and valid directory\n",
    "if refresh_directories:\n",
    "    log.info('Create directory structure and validation files')\n",
    "    sub_dirs = os.listdir(os.path.join(path, 'train-all'))\n",
    "    if '.DS_Store' in sub_dirs: sub_dirs.remove('.DS_Store')\n",
    "    refresh_directory_structure('pseudo/train', sub_dirs)\n",
    "    refresh_directory_structure('pseudo/valid', sub_dirs)\n",
    "    refresh_directory_structure('pseudo/test', ['test'])\n",
    "    for c,row in enumerate(csv.DictReader(open('../image_validation_set.csv'))):\n",
    "        value = 'pseudo/valid' if row['Validation'] == '1' else 'pseudo/train'\n",
    "        name_from = os.path.join(path, 'train-all', row['SubDirectory'], row['file_name'])\n",
    "        name_to   = os.path.join(path, value, row['SubDirectory'], row['file_name'])\n",
    "        shutil.copyfile(name_from, name_to)   \n",
    "    copy_tree(os.path.join(path, 'test'), os.path.join(path, 'pseudo/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.073193</td>\n",
       "      <td>0.030304</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.875060</td>\n",
       "      <td>YFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00053.jpg</td>\n",
       "      <td>0.885459</td>\n",
       "      <td>0.018413</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.061516</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>ALB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00071.jpg</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.910044</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>LAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_00007.jpg  0.073193  0.030304  0.007515  0.007025  0.001001  0.002952   \n",
       "1  img_00053.jpg  0.885459  0.018413  0.011608  0.004756  0.001013  0.061516   \n",
       "2  img_00071.jpg  0.067176  0.006945  0.003022  0.910044  0.001001  0.005329   \n",
       "\n",
       "      SHARK       YFT class  \n",
       "0  0.002951  0.875060   YFT  \n",
       "1  0.003243  0.013992   ALB  \n",
       "2  0.002918  0.003566   LAG  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use our best some to idenify high confidence test images\n",
    "best_sub = pd.read_csv(\"../best_sub.csv\")\n",
    "hiconf_test = best_sub[best_sub.drop(['image'], axis=1).apply(np.max, axis=1)>sub_cutoff].reset_index(drop=True)\n",
    "hiconf_test['class'] = hiconf_test.drop(['image'], axis=1).idxmax(axis = 1)\n",
    "hiconf_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:12: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.895428</td>\n",
       "      <td>740.284363</td>\n",
       "      <td>264.430939</td>\n",
       "      <td>1153.247192</td>\n",
       "      <td>521.133301</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00009.jpg</td>\n",
       "      <td>0.864695</td>\n",
       "      <td>607.911011</td>\n",
       "      <td>96.096519</td>\n",
       "      <td>929.203857</td>\n",
       "      <td>213.035217</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00018.jpg</td>\n",
       "      <td>0.886466</td>\n",
       "      <td>651.871094</td>\n",
       "      <td>118.684822</td>\n",
       "      <td>1016.892090</td>\n",
       "      <td>220.451233</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image     proba          x0          y0           x1          y1  \\\n",
       "0  img_00007.jpg  0.895428  740.284363  264.430939  1153.247192  521.133301   \n",
       "1  img_00009.jpg  0.864695  607.911011   96.096519   929.203857  213.035217   \n",
       "2  img_00018.jpg  0.886466  651.871094  118.684822  1016.892090  220.451233   \n",
       "\n",
       "  class  \n",
       "0  FISH  \n",
       "1  FISH  \n",
       "2  FISH  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we read in our high confidence boundary boxes. \n",
    "# Load up YOLO bounding boxes for each class\n",
    "all_files = glob.glob(os.path.join('../yolo_coords', \"*.txt\"))\n",
    "allFiles = [f for f in all_files if 'FISH' in f]\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=None, sep = \" \", names = ['image', 'proba', 'x0', 'y0', 'x1', 'y1'])\n",
    "    df['class'] = file_.split('_')[-1].split('.')[0]\n",
    "    list_.append(df)\n",
    "yolo_frame = pd.concat(list_)\n",
    "yolo_frame = yolo_frame[yolo_frame['proba']>yolo_cutoff].sort(['image'])\n",
    "# Just keep the highest confidence one\n",
    "yolo_frame = yolo_frame.loc[yolo_frame.groupby(['image'])['proba'].idxmax()].reset_index(drop=True)\n",
    "yolo_frame['image'] = yolo_frame['image'] + '.jpg'\n",
    "yolo_frame[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((459, 10), (360, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the innder join of each as we need the labels and the boundary box\n",
    "yolo_frame = yolo_frame[yolo_frame['image'].isin(hiconf_test['image'].tolist())].reset_index(drop=True)\n",
    "hiconf_test = hiconf_test[(hiconf_test['image'].isin(yolo_frame['image'].tolist())) | (hiconf_test['class']=='NoF')].reset_index(drop=True)\n",
    "hiconf_test.shape, yolo_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we do pseudo labelling by copying test images to pseudo/train data set\n",
    "for i in range(len(hiconf_test)):\n",
    "    row = hiconf_test.iloc[i].values.tolist()\n",
    "    img = row[0]\n",
    "    img_class = row[9]\n",
    "    name_from = os.path.join(path, 'test', 'test', img)\n",
    "    name_to   = os.path.join(path, 'pseudo/train', img_class, img)\n",
    "    shutil.copyfile(name_from, name_to) \n",
    "    #print (img, img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-20 23:09:28.847027] INFO: Logbook: Get VGG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 224, 224)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-20 23:09:31.945357] INFO: Logbook: Create VGG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 400, 700)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3545 images belonging to 8 classes.\n",
      "Found 691 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "[2017-03-20 23:09:32.458932] INFO: Logbook: Read filenames\n"
     ]
    }
   ],
   "source": [
    "# Read in our VGG pretrained model\n",
    "log.info('Get VGG')\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "# Create our VGG model\n",
    "log.info('Create VGG')\n",
    "vgg640 = Vgg16BN(load_size).model\n",
    "vgg640.pop()\n",
    "vgg640.input_shape, vgg640.output_shape\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# get labels\n",
    "(val_classes, trn_classes, val_labels, trn_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(path+ 'pseudo/')\n",
    "\n",
    "# Read in filenames\n",
    "log.info('Read filenames')\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the boxes\n",
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "for c in anno_classes:\n",
    "    j = json.load(open(os.path.join(path, 'box/{}_labels.json'.format(c)), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.895428</td>\n",
       "      <td>740.284363</td>\n",
       "      <td>264.430939</td>\n",
       "      <td>1153.247192</td>\n",
       "      <td>521.133301</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00053.jpg</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>485.583313</td>\n",
       "      <td>540.210205</td>\n",
       "      <td>675.545349</td>\n",
       "      <td>718.030029</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00071.jpg</td>\n",
       "      <td>0.822174</td>\n",
       "      <td>802.048096</td>\n",
       "      <td>210.676193</td>\n",
       "      <td>1054.677979</td>\n",
       "      <td>627.320862</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image     proba          x0          y0           x1          y1  \\\n",
       "0  img_00007.jpg  0.895428  740.284363  264.430939  1153.247192  521.133301   \n",
       "1  img_00053.jpg  0.851613  485.583313  540.210205   675.545349  718.030029   \n",
       "2  img_00071.jpg  0.822174  802.048096  210.676193  1054.677979  627.320862   \n",
       "\n",
       "  class  \n",
       "0  FISH  \n",
       "1  FISH  \n",
       "2  FISH  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_frame[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(yolo_frame)):\n",
    "    row = yolo_frame.iloc[i].values.tolist()\n",
    "    image, x, y, width, height = row[0], row[2], row[3], row[4]-row[2], row[5]-row[3]\n",
    "    bb_json[image] = {}\n",
    "    bb_json[image]['class'] = 'rect'\n",
    "    bb_json[image]['x'] = x\n",
    "    bb_json[image]['y'] = y\n",
    "    bb_json[image]['height'] = height\n",
    "    bb_json[image]['width'] = width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make it easy to find the nof dots, by putting themin the middle\n",
    "#empty_bbox = {'height': 0., 'width': 0., 'x': 1280/2., 'y': 720/2}\n",
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we convert the dictionary into an array, and convert the coordinates to our resized 224x224 images.\n",
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    conv_x = (load_size[1] / size[0])#(224. / size[0])\n",
    "    conv_y = (load_size[0] / size[1])#(224. / size[1])\n",
    "    bb[0] = bb[0]*conv_y\n",
    "    bb[1] = bb[1]*conv_x\n",
    "    bb[2] = max(bb[2]*conv_x, 0)\n",
    "    bb[3] = max(bb[3]*conv_y, 0)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_sizes = [PIL.Image.open(path+'pseudo/train/'+f).size for f in filenames]\n",
    "val_sizes = [PIL.Image.open(path+'pseudo/valid/'+f).size for f in val_filenames]\n",
    "tst_sizes = [PIL.Image.open(path+'pseudo/test/'+f).size for f in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_bbox = np.stack([convert_bb(bb_json[f], s) for f,s in zip(raw_filenames, trn_sizes)], \n",
    "                   ).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, val_sizes)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = trn_bbox[i]\n",
    "    plot(trn[i])\n",
    "    plt.gca().add_patch(create_rect(bb))\n",
    "\n",
    "#trn = get_data(path+'pseudo/train', load_size)\n",
    "#show_bb(1628)\n",
    "#del trn\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-03-20 23:09:34.959253] INFO: Logbook: Read in data\n",
      "Found 3545 images belonging to 8 classes.\n",
      "Found 691 images belonging to 8 classes.\n",
      "Found 3545 images belonging to 8 classes.\n",
      "Found 691 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "[2017-03-20 23:09:35.243218] INFO: Logbook: Fetch images\n",
      "[2017-03-20 23:09:35.244052] INFO: Logbook: Get VGG output\n",
      "[2017-03-20 23:09:35.244890] INFO: Logbook: Write VGG output\n",
      "Found 691 images belonging to 8 classes.\n",
      " 64/691 [=>............................] - ETA: 92s"
     ]
    }
   ],
   "source": [
    "log.info('Read in data')\n",
    "if not input_exists:\n",
    "\n",
    "    batches = get_batches(path+'pseudo/train', batch_size=batch_size)\n",
    "    val_batches = get_batches(path+'pseudo/valid', batch_size=batch_size*2, shuffle=False)\n",
    "    (val_classes, trn_classes, val_labels, trn_labels, \n",
    "        val_filenames, filenames, test_filenames) = get_classes(path+ 'pseudo/')\n",
    "    \n",
    "    # Fetch our large images \n",
    "    # Precompute the output of the convolutional part of VGG\n",
    "    log.info('Fetch images')\n",
    "    log.info('Get VGG output')\n",
    "    log.info('Write VGG output')\n",
    "    \n",
    "    val = get_data(path+'pseudo/valid', load_size)\n",
    "    conv_val_feat = vgg640.predict(val, batch_size=16, verbose=1)\n",
    "    save_array(path+'results/conv_val_pseudo_feat.dat', conv_val_feat)\n",
    "    del val, conv_val_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    trn = get_data(path+'pseudo/train', load_size)\n",
    "    conv_trn_feat = vgg640.predict(trn, batch_size=16, verbose=1)    \n",
    "    del trn\n",
    "    gc.collect()\n",
    "    save_array(path+'results/conv_trn_pseudo_feat.dat', conv_trn_feat) \n",
    "    del conv_trn_feat\n",
    "    gc.collect()\n",
    "    \n",
    "    test = get_data(path+'pseudo/test', load_size)\n",
    "    conv_test_feat = vgg640.predict(test, batch_size=16, verbose=1)\n",
    "    save_array(path+'results/conv_test_pseudo_feat.dat', conv_test_feat)     \n",
    "    del test, conv_test_feat\n",
    "    gc.collect()\n",
    "\n",
    "    # For memory purposes delete out the original train and validation\n",
    "    log.info('Clear up memory')\n",
    "    #del trn, val, test\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "conv_val_feat = load_array(path+'results/conv_val_pseudo_feat.dat')\n",
    "conv_trn_feat = load_array(path+'results/conv_trn_pseudo_feat.dat') \n",
    "conv_test_feat = load_array(path+'results/conv_test_pseudo_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if full:\n",
    "    conv_trn_feat = np.concatenate([conv_trn_feat, conv_val_feat])\n",
    "    trn_labels = np.concatenate([trn_labels, val_labels]) \n",
    "    trn_bbox = np.concatenate([trn_bbox, val_bbox])\n",
    "    \n",
    "# Our Convolutional Net Architecture\n",
    "log.info('Create and fit CNN')\n",
    "p=0.6\n",
    "# Set up the fully convolutional net (FCN); \n",
    "conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "nf=128; p=0. # No dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "nf = 512\n",
    "p  = 0.3\n",
    "def create_model():\n",
    "    inp = Input(conv_layers[-1].output_shape[1:])\n",
    "    x = MaxPooling2D()(inp)\n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = Convolution2D(nf,3,3, activation='relu', border_mode='same')(x)\n",
    "    x =   Dropout(p)(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    #x = MaxPooling2D()(x)\n",
    "    #x = ZeroPadding2D((1,1))(x)\n",
    "    #x = Convolution2D(nf,3,3, activation='relu', border_mode='same')(x)\n",
    "    #x =   Dropout(p)(x)\n",
    "    #x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = Convolution2D(nf,3,3, activation='relu', border_mode='same')(x)\n",
    "    x =   Dropout(p)(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x1 =   MaxPooling2D()(x)\n",
    "    x1 =   Convolution2D(8,3,3, border_mode='same')(x1)\n",
    "    x1 =   Dropout(p/2)(x1)\n",
    "    x1 =   GlobalAveragePooling2D()(x1)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x_bb = Dense(4, name='bb')(x)\n",
    "    x_class = Dense(8, activation='softmax', name='class')(x1)\n",
    "    return inp, x_bb, x_class\n",
    "\n",
    "## Set up the fully convolutional net (FCN); \n",
    "#conv_layers,_ = split_at(vgg640, Convolution2D)\n",
    "#nf=128; p=0. # No dropout\n",
    "\n",
    "model = []\n",
    "predsls = []\n",
    "pvalsls = []\n",
    "\n",
    "for ii in range(5):\n",
    "    inp, x_bb, x_class = create_model()\n",
    "    model.append(Model([inp], [x_bb, x_class]))\n",
    "    #model.summary()\n",
    "    model[ii].compile(Adam(lr=1e-3), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],\n",
    "                 loss_weights=[.001, 1.])\n",
    "    model[ii].fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=5, \n",
    "                 validation_data=(conv_val_feat, [val_bbox, val_labels]))\n",
    "    model[ii].optimizer.lr = 1e-4\n",
    "    model[ii].optimizer.loss_weights=[.00001, 1.]\n",
    "    model[ii].fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=2, \n",
    "                 validation_data=(conv_val_feat, [val_bbox, val_labels]))\n",
    "    model[ii].optimizer.lr = 1e-5\n",
    "\n",
    "    count = 0\n",
    "    while count < 8:\n",
    "        model[ii].fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=1, \n",
    "                     validation_data=(conv_val_feat, [val_bbox, val_labels]))\n",
    "        predsls.append(model[ii].predict(conv_test_feat, batch_size=batch_size)[1]) # or try 32 batch_size\n",
    "        pvalsls.append(model[ii].predict(conv_val_feat, batch_size=batch_size)[1])\n",
    "        val_score = \"%.3f\" % metrics.log_loss(val_labels, sum(pvalsls)/len(pvalsls))\n",
    "        acc_score = \"%.3f\" % accuracyfunc(val_labels, do_clip(sum(pvalsls)/len(pvalsls), clip))\n",
    "        log.info('Bagged Validation Logloss ' + str(val_score))\n",
    "        log.info('Bagged Validation Accuracy ' + str(acc_score))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = get_data(path+'pseudo/valid', load_size)\n",
    "pval_bbox = model[0].predict(conv_val_feat, batch_size=batch_size)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = val_bbox[i]\n",
    "    pbb = pval_bbox[i]\n",
    "    plot(val[i])\n",
    "    plt.gca().add_patch(create_rect(bb, color='red'))\n",
    "    plt.gca().add_patch(create_rect(pbb, color='yellow'))\n",
    "\n",
    "show_bb(350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metrics.log_loss(val_labels, do_clip(sum(pvalsls)/len(pvalsls), .9999))\n",
    "preds = sum(predsls)/len(predsls)\n",
    "subm = do_clip(preds, clip)\n",
    "\n",
    "if full:\n",
    "    subm_name = path+'results/subm_full_pseudo_' + timestr + 'B.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = path+'results/subm_part_pseudo_' + timestr + 'B.csv' #'.csv.gz'\n",
    "\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "log.info('Done - files @ ' + subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
